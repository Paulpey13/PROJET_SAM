{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipu_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>start_ipu</th>\n",
       "      <th>stop_ipu</th>\n",
       "      <th>text_ipu</th>\n",
       "      <th>is_main_speaker</th>\n",
       "      <th>turn_at_start</th>\n",
       "      <th>turn_after</th>\n",
       "      <th>turn_start_word</th>\n",
       "      <th>yield_at_end</th>\n",
       "      <th>request_at_start</th>\n",
       "      <th>start_words</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>duration</th>\n",
       "      <th>text_words</th>\n",
       "      <th>request_after_word</th>\n",
       "      <th>turn_after_word</th>\n",
       "      <th>is_ipu_end</th>\n",
       "      <th>dyad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AA</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.840</td>\n",
       "      <td>tu as</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.84</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.72</td>\n",
       "      <td>0.18</td>\n",
       "      <td>tu</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>transcr\\AAOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>AA</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.840</td>\n",
       "      <td>tu as</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.84</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.12</td>\n",
       "      <td>as</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>transcr\\AAOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>OR</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.825</td>\n",
       "      <td>mh ouais si tu veux</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.44</td>\n",
       "      <td>0.30</td>\n",
       "      <td>mh</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>transcr\\AAOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ipu_id speaker  start_ipu  stop_ipu             text_ipu  is_main_speaker  \\\n",
       "0       0      AA       4.54     4.840                tu as             True   \n",
       "1       0      AA       4.54     4.840                tu as             True   \n",
       "2       1      OR       5.14     5.825  mh ouais si tu veux             True   \n",
       "\n",
       "   turn_at_start  turn_after  turn_start_word  yield_at_end  request_at_start  \\\n",
       "0          False        True             4.84          True             False   \n",
       "1          False        True             4.84          True             False   \n",
       "2           True       False              NaN         False              True   \n",
       "\n",
       "   start_words  stop_words  duration text_words  request_after_word  \\\n",
       "0         4.54        4.72      0.18         tu               False   \n",
       "1         4.72        4.84      0.12         as               False   \n",
       "2         5.14        5.44      0.30         mh                True   \n",
       "\n",
       "   turn_after_word is_ipu_end          dyad  \n",
       "0            False      False  transcr\\AAOR  \n",
       "1            False       True  transcr\\AAOR  \n",
       "2            False      False  transcr\\AAOR  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import transformers\n",
    "import load_data\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertTokenizer, CamembertModel, CamembertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import os\n",
    "from training_audio_model import *\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu') # GPU ou CPU\n",
    "print(torch.cuda.is_available())\n",
    "# Chargement des données\n",
    "transcr_path='paco-cheese/transcr'\n",
    "data=load_data.load_all_ipus(folder_path=transcr_path,load_words=True)\n",
    "\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "from utils import *\n",
    "y=create_y(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paco-cheese/audio/2_channels/AA_OR.wav\n",
      "982587\n",
      "paco-cheese/audio/2_channels/AC_MZ.wav\n",
      "897019\n",
      "paco-cheese/audio/2_channels/AS_EP.wav\n",
      "965947\n",
      "paco-cheese/audio/2_channels/AW_CG.wav\n",
      "1033723\n",
      "paco-cheese/audio/2_channels/BE_CR.wav\n",
      "1036379\n",
      "paco-cheese/audio/2_channels/CM_MCC.wav\n",
      "969659\n",
      "paco-cheese/audio/2_channels/ER_AG.wav\n",
      "892283\n",
      "paco-cheese/audio/2_channels/FB_CB.wav\n",
      "1119451\n",
      "paco-cheese/audio/2_channels/FS_MG.wav\n",
      "932987\n",
      "paco-cheese/audio/2_channels/JA_EA.wav\n",
      "1012361\n",
      "paco-cheese/audio/2_channels/JDS_LS.wav\n",
      "1056539\n",
      "paco-cheese/audio/2_channels/LJ_JL.wav\n",
      "1591419\n",
      "paco-cheese/audio/2_channels/JR_BG.wav\n",
      "1109339\n",
      "paco-cheese/audio/2_channels/JS_CL.wav\n",
      "991483\n",
      "paco-cheese/audio/2_channels/LB_MA.wav\n",
      "1055995\n",
      "paco-cheese/audio/2_channels/LE_LB.wav\n",
      "1244379\n",
      "paco-cheese/audio/2_channels/LJ_JL.wav\n",
      "1591419\n",
      "paco-cheese/audio/2_channels/LP_MA.wav\n",
      "1183131\n",
      "paco-cheese/audio/2_channels/LS_NA.wav\n",
      "1302523\n",
      "paco-cheese/audio/2_channels/MA_PC.wav\n",
      "1044155\n",
      "paco-cheese/audio/2_channels/MC_MRH.wav\n",
      "987259\n",
      "paco-cheese/audio/2_channels/MD_AD.wav\n",
      "1291003\n",
      "paco-cheese/audio/2_channels/ML_HE.wav\n",
      "1262651\n",
      "paco-cheese/audio/2_channels/NL_PG.wav\n",
      "1216731\n",
      "paco-cheese/audio/2_channels/PO_MH.wav\n",
      "1119579\n",
      "paco-cheese/audio/2_channels/PR_EM.wav\n",
      "1134811\n",
      "paco-cheese/audio/2_channels/RPA_BN.wav\n",
      "1127227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1600\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1280\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1920\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1376\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1824\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=960\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1248\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=800\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1120\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=992\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1888\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1440\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1536\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1312\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1184\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1408\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1632\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1760\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1504\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1952\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=2016\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=736\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1792\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_files_path = 'paco-cheese/audio/2_channels/'\n",
    "audio_segments = extract_audio_segments(data,audio_files_path)\n",
    "X = np.array([extract_features(segment) for segment in audio_segments])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AudioDataset(X, y)\n",
    "train_size=int(0.8*len(dataset))\n",
    "X_train = dataset[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "\n",
    "# on prends 4 fois plus de données de test afin de s'assurer de l'efficacité du modèle\n",
    "X_test = dataset[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# Divisez les données en ensembles d'entraînement et de test\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "train_dataset = AudioDataset(X_train, y_train)\n",
    "test_dataset = AudioDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110544\n",
      "22109\n"
     ]
    }
   ],
   "source": [
    "print(len(y))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.8584121695443728\n",
      "Confusion Matrix:\n",
      "[[17554  2776]\n",
      " [  900   879]]\n",
      "Nombre d'éléments de classe 0 détectés : 17554 sur 20330\n",
      "Nombre d'éléments de classe 1 détectés : 879 sur 1779\n"
     ]
    }
   ],
   "source": [
    "model=torch.load('modele/model_audio')\n",
    "all_preds_audio,all_labels=predition_model_audio(model,test_loader,device)\n",
    "f1 = f1_score(all_labels, all_preds_audio, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds_audio)\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Calculer et afficher les informations spécifiques\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "detected_class_0 = conf_matrix[0, 0]  # Vrais positifs pour la classe 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # Vrais positifs pour la classe 1\n",
    "\n",
    "print(f'Nombre d\\'éléments de classe 0 détectés : {detected_class_0} sur {total_class_0}')\n",
    "print(f'Nombre d\\'éléments de classe 1 détectés : {detected_class_1} sur {total_class_1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22109\n"
     ]
    }
   ],
   "source": [
    "#model = importation\n",
    "\n",
    "all_preds_audio,all_labels_audio=predition_model_audio(model,test_loader,device)\n",
    "print(len(all_preds_audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation données texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from training_text_model import *\n",
    "\n",
    "\n",
    "features = data['text_words'].to_numpy().reshape(-1).tolist()  \n",
    "\n",
    "features = [word if not pd.isnull(word) else '[UNK]' for word in features]\n",
    "train_size = int(len(features) * 0.8)\n",
    "train_size=train_size\n",
    "X_train = features[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "indices = [i for i, x in enumerate(y_train) if x == 1]\n",
    "\n",
    "X_test = features[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "window_size = 5\n",
    "\n",
    "\n",
    "X_train = create_sequences(X_train)\n",
    "X_test = create_sequences(X_test)\n",
    "# Paramètres\n",
    "model_name = 'camembert-base'\n",
    "max_length = 256\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Tokenizer pour CamemBERT\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "\n",
    "#y_train = y_train[window_size:] if len(y_train) > window_size else y_train\n",
    "#y_test = y_test[window_size:] if len(y_test) > window_size else y_test\n",
    "\n",
    "# Création des datasets et dataloaders\n",
    "train_dataset = TextDataset(X_train, y_train, tokenizer, max_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TextDataset(X_test, y_test, tokenizer, max_length)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction modèle texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.7958142033852643\n",
      "Confusion Matrix:\n",
      "[[15591  4739]\n",
      " [  950   829]]\n",
      "Nombre d'éléments de classe 0 détectés : 15591 sur 20330\n",
      "Nombre d'éléments de classe 1 détectés : 829 sur 1779\n"
     ]
    }
   ],
   "source": [
    "all_preds_text = []\n",
    "all_labels = []\n",
    "model= torch.load('modele/camembert_epoch_3.bin')\n",
    "model.eval()\n",
    "all_preds_text,all_labels = prediction_model_text(model,test_loader,device)\n",
    "f1 = f1_score(all_labels, all_preds_text, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds_text)\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Calculer et afficher les informations spécifiques\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "detected_class_0 = conf_matrix[0, 0]  # Vrais positifs pour la classe 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # Vrais positifs pour la classe 1\n",
    "\n",
    "print(f'Nombre d\\'éléments de classe 0 détectés : {detected_class_0} sur {total_class_0}')\n",
    "print(f'Nombre d\\'éléments de classe 1 détectés : {detected_class_1} sur {total_class_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prédiction early fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_preds_audio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Combinaison des prédictions avec une opération \"AND\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m combined_preds_and \u001b[38;5;241m=\u001b[39m [pred_text \u001b[38;5;129;01mand\u001b[39;00m pred_audio \u001b[38;5;28;01mfor\u001b[39;00m pred_text, pred_audio \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(all_preds_text, \u001b[43mall_preds_audio\u001b[49m)]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_preds_audio' is not defined"
     ]
    }
   ],
   "source": [
    "# Combinaison des prédictions avec une opération \"AND\"\n",
    "combined_preds_and = [pred_text and pred_audio for pred_text, pred_audio in zip(all_preds_text, all_preds_audio)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.8677478673033029\n",
      "Confusion Matrix:\n",
      "[[18025  2305]\n",
      " [ 1007   772]]\n",
      "Nombre d'éléments de classe 0 détectés : 19791 sur 20330\n",
      "Nombre d'éléments de classe 1 détectés : 314 sur 1779\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(all_labels, combined_preds_and, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_labels, combined_preds_and)\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Calculer et afficher les informations spécifiques\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "detected_class_0 = conf_matrix[0, 0]  # Vrais positifs pour la classe 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # Vrais positifs pour la classe 1\n",
    "\n",
    "print(f'Nombre d\\'éléments de classe 0 détectés : {detected_class_0} sur {total_class_0}')\n",
    "print(f'Nombre d\\'éléments de classe 1 détectés : {detected_class_1} sur {total_class_1}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
