{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import transformers\n",
    "from utils import * \n",
    "import load_data\n",
    "from transformers import BertModel, BertTokenizer, CamembertModel, CamembertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import os\n",
    "from training_audio_model import *\n",
    "\n",
    "# Set the device for GPU usage\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Load the data\n",
    "transcr_path = 'paco-cheese/transcr'\n",
    "data = load_data.load_all_ipus(folder_path=transcr_path, load_words=True)\n",
    "\n",
    "# Display the first 3 entries of the data\n",
    "data[:3]\n",
    "\n",
    "# Import additional utilities and models\n",
    "from utils import *\n",
    "from training_text_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y de base\n",
      "9131\n",
      "7269\n",
      "y yield at\n",
      "3090\n",
      "13310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"y turn after\")\\ny=create_y_turn_after(df) # Création de la target\\nprint(y.count(1))\\nprint(y.count(0))\\nprint(len(y))\\nprint(len(data))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the target variable 'y' from the DataFrame\n",
    "y = create_y(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define audio files path\n",
    "audio_files_path = 'paco-cheese/audio/2_channels/'\n",
    "\n",
    "# Extract audio segments\n",
    "audio_segments = extract_audio_segments(data,audio_files_path)\n",
    "\n",
    "# Extract features from audio segments\n",
    "X = np.array([extract_features(segment) for segment in audio_segments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AudioDataset from the features and labels\n",
    "dataset = AudioDataset(X, y)\n",
    "\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Determine the size of the training set (80% of the total data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "\n",
    "# Split the features and labels into training and testing sets\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Create AudioDatasets for the training and testing sets\n",
    "train_dataset = AudioDataset(X_train, y_train)\n",
    "test_dataset = AudioDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoaders for the training and testing sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader_audio = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "print(len(y))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = torch.load('modele/model_audio')\n",
    "\n",
    "# Use the model to make predictions on the test set\n",
    "all_preds_audio, all_labels = predition_model_audio(model, test_loader_audio, device, proba=False)\n",
    "\n",
    "# Calculate the weighted F1 score\n",
    "f1 = f1_score(all_labels, all_preds_audio, average='weighted')\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds_audio)\n",
    "\n",
    "# Print the F1 score and confusion matrix\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Calculate the total number of instances for each class\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "\n",
    "# Calculate the number of correctly detected instances for each class\n",
    "detected_class_0 = conf_matrix[0, 0]  # True positives for class 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # True positives for class 1\n",
    "\n",
    "# Print the number of correctly detected instances for each class\n",
    "print(f'Number of class 0 instances detected: {detected_class_0} out of {total_class_0}')\n",
    "print(f'Number of class 1 instances detected: {detected_class_1} out of {total_class_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make predictions on the test set, return probabilities\n",
    "all_preds_audio, all_labels_audio = predition_model_audio(model, test_loader_audio, device, proba=True)\n",
    "\n",
    "# Print the predicted probabilities and their count\n",
    "print(all_preds_audio)\n",
    "print(len(all_preds_audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation données texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'text_words' column of the data to a list\n",
    "features = data['text_words'].to_numpy().reshape(-1).tolist()  \n",
    "\n",
    "# Replace any null values in the features with '[UNK]'\n",
    "features = [word if not pd.isnull(word) else '[UNK]' for word in features]\n",
    "\n",
    "# Determine the size of the training set (80% of the total data)\n",
    "train_size = int(len(features) * 0.8)\n",
    "\n",
    "# Split the features and labels into training and testing sets\n",
    "X_train = features[:train_size]\n",
    "y_train = y[:train_size]\n",
    "X_test = features[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# Define the window size for creating sequences\n",
    "window_size = 5\n",
    "\n",
    "# Create sequences from the training and testing features\n",
    "X_train = create_sequences(X_train)\n",
    "X_test = create_sequences(X_test)\n",
    "\n",
    "# Define the parameters for the model\n",
    "model_name = 'camembert-base'\n",
    "max_length = 256\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the tokenizer for CamemBERT\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Create TextDatasets and DataLoaders for the training and testing sets\n",
    "train_dataset = TextDataset(X_train, y_train, tokenizer, max_length)\n",
    "train_loader_text = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = TextDataset(X_test, y_test, tokenizer, max_length)\n",
    "test_loader_text = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction modèle texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = torch.load('modele/camembert_epoch_3.bin')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Use the model to make predictions on the test set\n",
    "all_preds_text, all_labels = prediction_model_text(model, test_loader_text, device, proba=False)\n",
    "\n",
    "# Calculate the weighted F1 score\n",
    "f1 = f1_score(all_labels, all_preds_text, average='weighted')\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds_text)\n",
    "\n",
    "# Print the F1 score and confusion matrix\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Calculate the total number of instances for each class\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "\n",
    "# Calculate the number of correctly detected instances for each class\n",
    "detected_class_0 = conf_matrix[0, 0]  # True positives for class 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # True positives for class 1\n",
    "\n",
    "# Print the number of correctly detected instances for each class\n",
    "print(f'Number of class 0 instances detected: {detected_class_0} out of {total_class_0}')\n",
    "print(f'Number of class 1 instances detected: {detected_class_1} out of {total_class_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prédiction late fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained text model\n",
    "model_text = torch.load('modele/camembert_epoch_3.bin')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_text.eval()\n",
    "\n",
    "# Use the model to make predictions on the test set, return probabilities\n",
    "all_preds_text_proba, all_labels = prediction_model_text(model_text, test_loader_text, device, proba=True)\n",
    "\n",
    "# Combine the predictions from the text and audio models using a logical AND operation\n",
    "# combined_preds_and = [pred_text and pred_audio for pred_text, pred_audio in zip(all_preds_text, all_preds_audio)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained audio model\n",
    "model_audio = torch.load('modele/model_audio')\n",
    "\n",
    "# Use the model to make predictions on the test set, return probabilities\n",
    "all_preds_audio_proba, all_labels_audio = predition_model_audio(model_audio, test_loader_audio, device, proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "print(all_preds_audio)\n",
    "print(all_preds_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the probability arrays from the audio and text models\n",
    "sum_array = np.add(all_preds_audio_proba, all_preds_text_proba)\n",
    "\n",
    "# Determine the class (0 or 1) for each list by finding the index of the maximum value\n",
    "combined_preds = np.argmax(sum_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weighted F1 score for the combined predictions\n",
    "f1 = f1_score(all_labels, combined_preds, average='weighted')\n",
    "\n",
    "# Generate the confusion matrix for the combined predictions\n",
    "conf_matrix = confusion_matrix(all_labels, combined_preds)\n",
    "\n",
    "# Print the F1 score and confusion matrix\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Calculate the total number of instances for each class\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "\n",
    "# Calculate the number of correctly detected instances for each class\n",
    "detected_class_0 = conf_matrix[0, 0]  # True positives for class 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # True positives for class 1\n",
    "\n",
    "# Print the number of correctly detected instances for each class\n",
    "print(f'Number of class 0 instances detected: {detected_class_0} out of {total_class_0}')\n",
    "print(f'Number of class 1 instances detected: {detected_class_1} out of {total_class_1}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
