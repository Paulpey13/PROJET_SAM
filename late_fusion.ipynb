{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipu_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>text</th>\n",
       "      <th>is_main_speaker</th>\n",
       "      <th>turn_at_start</th>\n",
       "      <th>turn_after</th>\n",
       "      <th>turn_start_word</th>\n",
       "      <th>yield_at_end</th>\n",
       "      <th>request_at_start</th>\n",
       "      <th>dyad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AA</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.840</td>\n",
       "      <td>tu as</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.84</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>transcr\\AAOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>OR</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.825</td>\n",
       "      <td>mh ouais si tu veux</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>transcr\\AAOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>OR</td>\n",
       "      <td>6.62</td>\n",
       "      <td>7.010</td>\n",
       "      <td>frog joke</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>transcr\\AAOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ipu_id speaker  start   stop                 text  is_main_speaker  \\\n",
       "0       0      AA   4.54  4.840                tu as             True   \n",
       "1       1      OR   5.14  5.825  mh ouais si tu veux             True   \n",
       "2       2      OR   6.62  7.010            frog joke             True   \n",
       "\n",
       "   turn_at_start  turn_after  turn_start_word  yield_at_end  request_at_start  \\\n",
       "0          False        True             4.84          True             False   \n",
       "1           True       False              NaN         False              True   \n",
       "2          False       False              NaN         False             False   \n",
       "\n",
       "           dyad  \n",
       "0  transcr\\AAOR  \n",
       "1  transcr\\AAOR  \n",
       "2  transcr\\AAOR  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import transformers\n",
    "from utils import * \n",
    "import load_data\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertTokenizer, CamembertModel, CamembertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import os\n",
    "from training_audio_model import *\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu') # GPU ou CPU\n",
    "print(torch.cuda.is_available())\n",
    "# Chargement des données\n",
    "transcr_path='paco-cheese/transcr'\n",
    "data=load_data.load_all_ipus(folder_path=transcr_path,load_words=False)\n",
    "\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y de base\n",
      "9131\n",
      "7269\n",
      "y yield at\n",
      "3090\n",
      "13310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"y turn after\")\\ny=create_y_turn_after(df) # Création de la target\\nprint(y.count(1))\\nprint(y.count(0))\\nprint(len(y))\\nprint(len(data))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"y de base\")\n",
    "y=create_y(df) # Création de la target\n",
    "print(y.count(1))\n",
    "print(y.count(0))\n",
    "\n",
    "\n",
    "print(\"y yield at\")\n",
    "y=create_y_yield_at(df) # Création de la target\n",
    "print(y.count(1))\n",
    "print(y.count(0))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"y turn after\")\n",
    "y=create_y_turn_after(df) # Création de la target\n",
    "print(y.count(1))\n",
    "print(y.count(0))\n",
    "print(len(y))\n",
    "print(len(data))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1920\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1280\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1120\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1888\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1408\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1600\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1312\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=960\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=992\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_files_path = 'paco-cheese/audio/2_channels/'\n",
    "audio_segments = extract_audio_segments(data,audio_files_path)\n",
    "X = np.array([extract_features(segment) for segment in audio_segments])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AudioDataset(X, y)\n",
    "train_size=int(0.8*len(dataset))\n",
    "X_train = dataset[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "\n",
    "X_test = dataset[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# Divisez les données en ensembles d'entraînement et de test\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "train_dataset = AudioDataset(X_train, y_train)\n",
    "test_dataset = AudioDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader_audio = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16400\n",
      "3280\n"
     ]
    }
   ],
   "source": [
    "print(len(y))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.6974046347065446\n",
      "Confusion Matrix:\n",
      "[[1996  625]\n",
      " [ 417  242]]\n",
      "Nombre d'éléments de classe 0 détectés : 1996 sur 2621\n",
      "Nombre d'éléments de classe 1 détectés : 242 sur 659\n"
     ]
    }
   ],
   "source": [
    "model=torch.load('modele/model_audio')\n",
    "all_preds_audio,all_labels=predition_model_audio(model,test_loader_audio,device,proba=False)\n",
    "f1 = f1_score(all_labels, all_preds_audio, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds_audio)\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "detected_class_0 = conf_matrix[0, 0]  # Vrais positifs pour la classe 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # Vrais positifs pour la classe 1\n",
    "\n",
    "print(f'Nombre d\\'éléments de classe 0 détectés : {detected_class_0} sur {total_class_0}')\n",
    "print(f'Nombre d\\'éléments de classe 1 détectés : {detected_class_1} sur {total_class_1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.35173398 -0.08440793]\n",
      " [ 0.24370825 -0.01410505]\n",
      " [ 0.30740234 -0.07149775]\n",
      " ...\n",
      " [ 0.6129222  -0.35087425]\n",
      " [ 0.38541636 -0.1861543 ]\n",
      " [ 1.442695   -1.3897967 ]]\n",
      "3280\n"
     ]
    }
   ],
   "source": [
    "#model = importation\n",
    "\n",
    "all_preds_audio,all_labels_audio=predition_model_audio(model,test_loader_audio,device,proba=True)\n",
    "print(all_preds_audio)\n",
    "print(len(all_preds_audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation données texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from training_text_model import *\n",
    "\n",
    "seed = 42\n",
    "\n",
    "data_text=create_sequences(data)\n",
    "# Divisez les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_text, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Paramètres\n",
    "model_name = 'camembert-base'\n",
    "max_length = 256\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Tokenizer pour CamemBERT\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Création des datasets et dataloaders pour le texte\n",
    "train_dataset = TextDataset(X_train, y_train, tokenizer, max_length)\n",
    "train_loader_text = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TextDataset(X_test, y_test, tokenizer, max_length)\n",
    "test_loader_text = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction modèle texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.3306982872200263\n",
      "Confusion Matrix:\n",
      "[[ 746 1926]\n",
      " [ 106  502]]\n",
      "Nombre d'éléments de classe 0 détectés : 746 sur 2672\n",
      "Nombre d'éléments de classe 1 détectés : 502 sur 608\n"
     ]
    }
   ],
   "source": [
    "all_preds_text = []\n",
    "all_labels = []\n",
    "model= torch.load('modele/camembert_epoch_3.bin')\n",
    "model.eval()\n",
    "all_preds_text,all_labels = prediction_model_text(model,test_loader_text,device,proba=False)\n",
    "f1 = f1_score(all_labels, all_preds_text)#, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds_text)\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "detected_class_0 = conf_matrix[0, 0]  # Vrais positifs pour la classe 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # Vrais positifs pour la classe 1\n",
    "\n",
    "print(f'Nombre d\\'éléments de classe 0 détectés : {detected_class_0} sur {total_class_0}')\n",
    "print(f'Nombre d\\'éléments de classe 1 détectés : {detected_class_1} sur {total_class_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prédiction late fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_text= torch.load('modele/camembert_epoch_1.bin')\n",
    "model_text.eval()\n",
    "all_preds_text_proba,all_labels = prediction_model_text(model_text,test_loader_text,device,proba=True)\n",
    "\n",
    "#combined_preds_and = [pred_text and pred_audio for pred_text, pred_audio in zip(all_preds_text, all_preds_audio)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_audio=torch.load('modele/model_audio')\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "all_preds_audio_proba,all_labels_audio=predition_model_audio(model_audio,test_loader_audio,device,proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.35173398 -0.08440793]\n",
      " [ 0.24370825 -0.01410505]\n",
      " [ 0.30740234 -0.07149775]\n",
      " ...\n",
      " [ 0.6129222  -0.35087425]\n",
      " [ 0.38541636 -0.1861543 ]\n",
      " [ 1.442695   -1.3897967 ]]\n",
      "[0 0 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(all_preds_audio)\n",
    "print(all_preds_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Addition des tableaux de probabilités\n",
    "sum_array = np.add(all_preds_audio_proba, all_preds_text_proba)\n",
    "\n",
    "# Trouver la classe pour chaque liste (0 ou 1)\n",
    "combined_preds = np.argmax(sum_array, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.46661614590325806\n",
      "Confusion Matrix:\n",
      "[[ 936 1736]\n",
      " [ 149  459]]\n",
      "Nombre d'éléments de classe 0 détectés : 936 sur 2672\n",
      "Nombre d'éléments de classe 1 détectés : 459 sur 608\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(all_labels, combined_preds, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_labels, combined_preds)\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "detected_class_0 = conf_matrix[0, 0]  # Vrais positifs pour la classe 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # Vrais positifs pour la classe 1\n",
    "\n",
    "print(f'Nombre d\\'éléments de classe 0 détectés : {detected_class_0} sur {total_class_0}')\n",
    "print(f'Nombre d\\'éléments de classe 1 détectés : {detected_class_1} sur {total_class_1}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
