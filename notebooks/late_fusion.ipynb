{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\Documents\\GitHub\\PROJET_SAM\\notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1920\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1280\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1120\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1888\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1408\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1600\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1312\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=960\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=992\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "src = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "#src = os.path.abspath(os.path.join(src, os.pardir))\n",
    "#src = os.path.abspath(os.path.join(src, os.pardir))\n",
    "sys.path.append(src)\n",
    "\n",
    "from src.pipeline_late_fusion_audio_text import *\n",
    "\n",
    "training_eval_models(num_epochs=1,seed=1,device='gpu',model_name='test',patience=1,class_weight=[[1.0,4.0]],task=\"yield\",save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'training_audio_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtraining_audio_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     22\u001b[0m device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# GPU ou CPU\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'training_audio_model'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import transformers\n",
    "from utils import * \n",
    "import load_data\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel, BertTokenizer, CamembertModel, CamembertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import os\n",
    "from training_audio_model import *\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu') # GPU ou CPU\n",
    "print(torch.cuda.is_available())\n",
    "# Chargement des données\n",
    "transcr_path='paco-cheese/transcr'\n",
    "data=load_data.load_all_ipus(folder_path=transcr_path,load_words=False)\n",
    "\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y de base\n",
      "9131\n",
      "7269\n",
      "y yield at\n",
      "3090\n",
      "13310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"y turn after\")\\ny=create_y_turn_after(df) # Création de la target\\nprint(y.count(1))\\nprint(y.count(0))\\nprint(len(y))\\nprint(len(data))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"y de base\")\n",
    "y=create_y(df) # Création de la target\n",
    "print(y.count(1))\n",
    "print(y.count(0))\n",
    "\n",
    "\n",
    "print(\"y yield at\")\n",
    "y=create_y_yield_at(df) # Création de la target\n",
    "print(y.count(1))\n",
    "print(y.count(0))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"y turn after\")\n",
    "y=create_y_turn_after(df) # Création de la target\n",
    "print(y.count(1))\n",
    "print(y.count(0))\n",
    "print(len(y))\n",
    "print(len(data))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1920\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1280\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1120\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1888\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1408\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1600\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1312\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=960\n",
      "  warnings.warn(\n",
      "C:\\Users\\victo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=992\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_files_path = 'paco-cheese/audio/2_channels/'\n",
    "audio_segments = extract_audio_segments(data,audio_files_path)\n",
    "X = np.array([extract_features(segment) for segment in audio_segments])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AudioDataset(X, y)\n",
    "train_size=int(0.8*len(dataset))\n",
    "X_train = dataset[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "\n",
    "X_test = dataset[train_size:]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# Divisez les données en ensembles d'entraînement et de test\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#test_size = len(dataset) - train_size\n",
    "#train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "train_dataset = AudioDataset(X_train, y_train)\n",
    "test_dataset = AudioDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader_audio = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16400\n",
      "3280\n"
     ]
    }
   ],
   "source": [
    "print(len(y))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.6974046347065446\n",
      "Confusion Matrix:\n",
      "[[1996  625]\n",
      " [ 417  242]]\n",
      "Nombre d'éléments de classe 0 détectés : 1996 sur 2621\n",
      "Nombre d'éléments de classe 1 détectés : 242 sur 659\n"
     ]
    }
   ],
   "source": [
    "model=torch.load('modele/model_audio')\n",
    "all_preds_audio,all_labels=predition_model_audio(model,test_loader_audio,device,proba=False)\n",
    "f1 = f1_score(all_labels, all_preds_audio, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds_audio)\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "detected_class_0 = conf_matrix[0, 0]  # Vrais positifs pour la classe 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # Vrais positifs pour la classe 1\n",
    "\n",
    "print(f'Nombre d\\'éléments de classe 0 détectés : {detected_class_0} sur {total_class_0}')\n",
    "print(f'Nombre d\\'éléments de classe 1 détectés : {detected_class_1} sur {total_class_1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.35173398 -0.08440793]\n",
      " [ 0.24370825 -0.01410505]\n",
      " [ 0.30740234 -0.07149775]\n",
      " ...\n",
      " [ 0.6129222  -0.35087425]\n",
      " [ 0.38541636 -0.1861543 ]\n",
      " [ 1.442695   -1.3897967 ]]\n",
      "3280\n"
     ]
    }
   ],
   "source": [
    "#model = importation\n",
    "\n",
    "all_preds_audio,all_labels_audio=predition_model_audio(model,test_loader_audio,device,proba=True)\n",
    "print(all_preds_audio)\n",
    "print(len(all_preds_audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation données texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from training_text_model import *\n",
    "\n",
    "seed = 42\n",
    "\n",
    "data_text=create_sequences(data)\n",
    "# Divisez les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_text, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Paramètres\n",
    "model_name = 'camembert-base'\n",
    "max_length = 256\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Tokenizer pour CamemBERT\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Création des datasets et dataloaders pour le texte\n",
    "train_dataset = TextDataset(X_train, y_train, tokenizer, max_length)\n",
    "train_loader_text = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TextDataset(X_test, y_test, tokenizer, max_length)\n",
    "test_loader_text = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction modèle texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.3306982872200263\n",
      "Confusion Matrix:\n",
      "[[ 746 1926]\n",
      " [ 106  502]]\n",
      "Nombre d'éléments de classe 0 détectés : 746 sur 2672\n",
      "Nombre d'éléments de classe 1 détectés : 502 sur 608\n"
     ]
    }
   ],
   "source": [
    "all_preds_text = []\n",
    "all_labels = []\n",
    "model= torch.load('modele/camembert_epoch_3.bin')\n",
    "model.eval()\n",
    "all_preds_text,all_labels = prediction_model_text(model,test_loader_text,device,proba=False)\n",
    "f1 = f1_score(all_labels, all_preds_text)#, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds_text)\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "detected_class_0 = conf_matrix[0, 0]  # Vrais positifs pour la classe 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # Vrais positifs pour la classe 1\n",
    "\n",
    "print(f'Nombre d\\'éléments de classe 0 détectés : {detected_class_0} sur {total_class_0}')\n",
    "print(f'Nombre d\\'éléments de classe 1 détectés : {detected_class_1} sur {total_class_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prédiction late fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_text= torch.load('modele/camembert_epoch_1.bin')\n",
    "model_text.eval()\n",
    "all_preds_text_proba,all_labels = prediction_model_text(model_text,test_loader_text,device,proba=True)\n",
    "\n",
    "#combined_preds_and = [pred_text and pred_audio for pred_text, pred_audio in zip(all_preds_text, all_preds_audio)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_audio=torch.load('modele/model_audio')\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "all_preds_audio_proba,all_labels_audio=predition_model_audio(model_audio,test_loader_audio,device,proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.35173398 -0.08440793]\n",
      " [ 0.24370825 -0.01410505]\n",
      " [ 0.30740234 -0.07149775]\n",
      " ...\n",
      " [ 0.6129222  -0.35087425]\n",
      " [ 0.38541636 -0.1861543 ]\n",
      " [ 1.442695   -1.3897967 ]]\n",
      "[0 0 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(all_preds_audio)\n",
    "print(all_preds_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Addition des tableaux de probabilités\n",
    "sum_array = np.add(all_preds_audio_proba, all_preds_text_proba)\n",
    "\n",
    "# Trouver la classe pour chaque liste (0 ou 1)\n",
    "combined_preds = np.argmax(sum_array, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.46661614590325806\n",
      "Confusion Matrix:\n",
      "[[ 936 1736]\n",
      " [ 149  459]]\n",
      "Nombre d'éléments de classe 0 détectés : 936 sur 2672\n",
      "Nombre d'éléments de classe 1 détectés : 459 sur 608\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(all_labels, combined_preds, average='weighted')\n",
    "conf_matrix = confusion_matrix(all_labels, combined_preds)\n",
    "print(f'Test F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "\n",
    "total_class_0 = np.sum(conf_matrix[0])\n",
    "total_class_1 = np.sum(conf_matrix[1])\n",
    "detected_class_0 = conf_matrix[0, 0]  # Vrais positifs pour la classe 0\n",
    "detected_class_1 = conf_matrix[1, 1]  # Vrais positifs pour la classe 1\n",
    "\n",
    "print(f'Nombre d\\'éléments de classe 0 détectés : {detected_class_0} sur {total_class_0}')\n",
    "print(f'Nombre d\\'éléments de classe 1 détectés : {detected_class_1} sur {total_class_1}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
